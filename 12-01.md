---
title: hive-3
date: 11-30 8.53 
categories: 日志
comments: "true"
tag: hive
---
# 内部和外部表和普通表和分区表

分区表 ： 提升查询效率的表

关于hive的查询 ： 对于普通表 则是要先读取所有的数据然后进行筛选的 ， 但是对于分区表，则是把数据进行分区，如果要查询的话，则是针对符合的数据进行查询

往往用分区表进行查询，普通表数据量较少的时候可以用

创建分区表 ：

```
create table order(

orderid int,

oredergg String

)

PARTITIONED BY (dt String)

row format delimited fields terminated by '\t'
```

show partitions 表名 //查看现在这个表的分区

修改分区  ：

删除分区  ：`alter table 表名 drop partition(分区列 = '分区名')`

创建分区 ： 在建表的时候创建

导入数据 ： load/insert

* load : load data (local) inpath '' (overwrite) into table 表名 partition (分区名称) ：数据列数如果对不上就会出现问题 : 加上overwrite则是把一个分区的数据给覆盖掉
* insert : insert into table partition(分区) ...
* insert into 是追加的
* 如果不要追加则要进行覆盖 insert 后面的 into 变成 overwrite

## 使用一个sql让所有数据落到对应的分区里

动态分区：相当于我们要进行分区的字段是我们的数据的字段，就可以直接用那个字段当我们的分区但是要打开一个开关

`set hive.exec.dynamic.partition.mode=nonstrict;`

静态分区：就是自己制定好分区的标题的

离线任务 ： 业务周期性 T+1

就是延迟一天处理

默认底层创建的是内部表

内部表 ： 受hive管控的 ： 如果有删表的操作，那么会清理干净，所有数据都会被删除

外部表 ： 如果被删除的情况下，只是hdfs上指向metastore的索引被删除了，源数据不会被删除 ，而且我们还可通过建表的方式让他们的索引再次关联上

创建外部表 ：

相互转换 ：

```
外部转内部
ALTER TABLE 外部表名字 SET TBLPROPERTIES ("EXTERNAL" = "true");

内部转外部
ALTER TABLE 外部表名字 SET TBLPROPERTIES ("EXTERNAL" = "false");
但是这上述的EXTERNAL 是不能小写的会造成失效的问题
```

# 复杂的数据类型

中小企业用的不多，，大企业用的多

会建表 ，会查询

maps: `MAP<primitive_type, data_type> `

数据如下 ：

```
1,zhangsan,father:xiaoming#mother:xiaohuang#brother:xiaoxu,28
2,lisi,father:mayun#mother:huangyi#brother:guanyu,22
3,wangwu,father:wangjianlin#mother:ruhua#sister:jingtian,29
4,mayun,father:mayongzhen#mother:angelababy,26
```

```
create table hive_map(
id int  comment '用户id',
name string comment '用户名字',
relation map<string,string> comment '家庭成员',
age int comment '年龄'
)
row format  delimited fields terminated by ','
collection items terminated by '#'
map keys terminated by ':';
```

arrays:  `ARRAY<data_type>`

数据

`zihan   beijing,shanghai,chengdu,dalian`

```
create table hive_array(
name String,
locations array<String>
)
row format delimited fields terminated by '\t'
collection items terminated by ',';
```

structs:`STRUCT<col_name : data_type [COMMENT col_comment], ...>`

数据

```
192.168.1.1#zhangsan:40
192.168.1.2#lisi:50
192.168.1.3#wangwu:60
192.168.1.4#zhaoliu:70
```

```
create table hive_struct(
ip string,
userinfo STRUCT<name:string,age:int>
)
row format  delimited fields terminated by '#'
collection items terminated by ':';
```

# 数据形式的不同使用方法

## array

案例分析：

1.查询每个用户第一个工作地点？

select  name ,locations[0] as first_loc_work from  hive_array;

2.查询每个人 工作地点的数量

select  name , size(locations) from  hive_array ;

3.查询在shanghai 工作的有哪些人

select  * from hive_array  where array_contains(locations,'shanghai');

### 行转列

思路是先把一个array的元素炸开，然后通过显示出来

显示手段 ： LATERAL VIEW（侧写视图）

* LATERAL VIEW udtf(expression) tableAlias AS columnAlias
* udtf : 一进多出
* FROM baseTable (lateralView)*
* 最终代码 ：

  ```sql
  select name,location
  from hive_array lateral view explode(locations) loc_table as location;
  ```

## map

需求： 1.查询表中每个人的father的名字

`select id,name,age,relation['father'] as father from hive_map;`

2.查询表中 每个人的家庭成员   keys

`select id,name,age,map_keys(relation) as members from hive_map;`

3.查询表中 每个人的家庭成员的名字 values

`select id,name,age,map_values(relation) as members from hive_map;`

4.查询表中 有brother的人以及brother的名字

```
select
 id,name,age,relation['brother'] as brother
from hive_map
where
relation['brother'] is not null;或者可以select
 id,name,age,relation['brother'] as brother
from hive_map
where
array_contains(map_keys(relation), 'brother');// map_key()函数的意思是可以把这个列的map的key当作array取出来
```

## structs

select ip,userinfo.name as name ,userinfo.age as age from hive_struct;

## 开窗函数 ：

* 分析函数：对开窗函数的分析的函数
  * rank : 使用方法 rank()over(partition by xx order by yy) as rk  : 如果有重复的数据，会丢失排名
  * dense_rank :使用方法同上 ： 如果有重复数据 ，则不会丢失排名 ：
  * row_number:同上 ： 排名相同且不会重复 ， 就是会顺序往下 ：

上述的常用手段 ： 求topn的排名

比如要求top3 的

作业 ：

统计每个店铺的uv

统计top3的用户记录

pv ： 页面的浏览量

uv ： 访客的次数
